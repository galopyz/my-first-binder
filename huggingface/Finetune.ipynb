{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94ad321",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca152da",
   "metadata": {},
   "source": [
    "Here, we finetune a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9d85b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a0b4d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is how we would finetune our model. However, it does not work on binder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb1b975",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bcba3ef2b549cd9765a3832c2b7f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b078e9f9884d6091e6d203d173779c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b999e4af09b4e298a885b6981ec0ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0326047a98294434a7fb0d3875859883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e0da192a7c497fa51762c3aa1d6ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/galopy/my-first-binder/.env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Does not work in binder\n",
    "import torch\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Same as before\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# This is new\n",
    "batch[\"labels\"] = torch.tensor([1, 1])\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5072a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using datasets, we can load our dataset. After downloading once, huggingface saves it in the local filesystem. Afterwards, we can just use the local version instead of redownloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95649d71",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/galopy/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74edc285cd8e488bb9314445a4ccbdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282bb2e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dataset has three components: train, validation, and test. While training, train and validation datasets are used. With train dataset, we train our model. With validation dataset, we validate our model by checking whether it is overfitting or not. After all the training, we use test dataset to check how our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97f560",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our train dataset has two sentences, label, and idx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16616cb7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0922fd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dataset's features tells us what kind of elements we have and what their meanings are. For instance, label tells us that 0 means 'not_equivalent,' and 1 means 'equivalent.' We can see that this model is trying to classify whether the two sentences mean the same or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10057b1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd4a62b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n",
       " 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n",
       " 'label': 0,\n",
       " 'idx': 16}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d885d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Tuition at four-year private colleges averaged $ 19,710 this year , up 6 percent from 2002 .',\n",
       " 'sentence2': 'For the current academic year , tuition at public colleges averaged $ 4,694 , up almost $ 600 from the year before .',\n",
       " 'label': 1,\n",
       " 'idx': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38150e83",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we have to tokenize our dataset. Using tokenizers directly like this is not recommended. It is not efficient, and tokenized_sentences_1 and tokenized_sentences_2 are not related here. These sentences are not ready to train. We need to combine two sentences and have token_type_ids for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bef2c3b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Bad way to tokenize\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120748f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=25, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=27, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=23, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences_1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07460df6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=25, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c2ae3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When two sentences are passed into a tokenizer, we get token_type_ids automatically. token_type_ids is similart to attention_mask, but it just distinguishes between sentences by using 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd621486",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af38692",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try tokenizing an element. First, we tokenize one sentence at a time, and tokenize both sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2548e5cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n",
       " 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n",
       " 'label': 0,\n",
       " 'idx': 16}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94fa46d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 24049, 2001, 2087, 3728, 3026, 3580, 2343, 2005, 1996, 9722, 1004, 4132, 9340, 12439, 2964, 2449, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(raw_train_dataset[15]['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceaeaa2f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3026, 3580, 2343, 4388, 24049, 1010, 3839, 2132, 1997, 1996, 9722, 1998, 4132, 9340, 12439, 2964, 3131, 1010, 2097, 2599, 1996, 2047, 9178, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(raw_train_dataset[15]['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dfa088f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 24049, 2001, 2087, 3728, 3026, 3580, 2343, 2005, 1996, 9722, 1004, 4132, 9340, 12439, 2964, 2449, 1012, 102, 3026, 3580, 2343, 4388, 24049, 1010, 3839, 2132, 1997, 1996, 9722, 1998, 4132, 9340, 12439, 2964, 3131, 1010, 2097, 2599, 1996, 2047, 9178, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(raw_train_dataset[15]['sentence1'], raw_train_dataset[15]['sentence2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bafcb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "token_type_ids have different values when both sentences are passed to tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bb6c9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can compare token_type_ids to tokens, and we can see that first sentences lasts until [SEP], and second one ends at [SEP]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "035a30f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sentence',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'one',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19712509",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['token_type_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84441349",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The most efficient way to preprocess datasets is to use <code>Dataset.map()</code>. To use it, we just need a function to perform on each element. So, we define <code>tokenize_function</code>. With this function, we tokenize two sentences with truncation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc8c321a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec3a05",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With lists of pairs of sentences, we can set batched as True, which provides a performance boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ba1fbc9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f0c6fa007240ccaa73af74fbf9a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7481d8d6bb4bb3851751be22e319d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36959dc347274196844f9621b252acb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce3f35b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b787d8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After turning strings into integers, we need to pad the inputs so that they have same lengths. We could have padded when we were tokenizing earlier, but padding all the inputs to match the length of the longest sentence is wasteful. We can just match the longest sentence of the batch instead. We do not have to make all sentences very long just because there is one long sentence in the whole dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92527592",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With <code>DataCollatorWithPadding</code>, we can do this easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40bc827e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e15f3c36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 59, 47, 67, 59, 50, 62, 32]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try it on samples with different lengths\n",
    "samples = tokenized_datasets[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "681ae18b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('sentence1', 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), ('sentence2', 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), ('label', 1), ('idx', 0), ('input_ids', [101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102]), ('token_type_ids', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait, what are the items?\n",
    "tokenized_datasets[\"train\"][0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e6a660",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All are padded to a length of 67\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebea88",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we are ready to finetune our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde8441",
   "metadata": {},
   "source": [
    "## Fine-tune our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
